# Web Scraping Project

## Description

This project is a Python-based web scraping application implemented in a Jupyter Notebook (`WebScraping.ipynb`). It extracts various types of data from a test webpage (`https://baraasalout.github.io/test.html`) and saves the results in CSV and JSON files. The script uses the `requests` library to fetch the webpage and `BeautifulSoup` from `bs4` for HTML parsing.

## Features

- Extracts text from `<h1>`, `<h2>`, `<p>`, and `<li>` tags and saves to `Extract_Text_Data.CSV`.
- Extracts table data and saves to `Extract_Table_Data.CSV`.
- Extracts book product details from a `<div class="book-products">` and saves to `Extract_Product_Information.json`.
- Extracts form input details and saves to `Extract_Form_Details.json`.
- Extracts links (`<a>`) and multimedia (`<iframe>`) data and saves to `Extract_Links_and_Multimedia.json`.
- Extracts featured product data using CSS selectors and saves to `Scraping_Challenge.json`.

## Requirements

- **Python**: 3.13.5
- **Libraries**:
  - `requests`
  - `beautifulsoup4`
  - `csv` (standard library)
  - `json` (standard library)
- **Jupyter Notebook**: For running the `.ipynb` file.

## Installation

1. Clone or download the repository.
2. Install dependencies:
   ```bash
   pip install requests beautifulsoup4
   ```
3. Ensure a Jupyter environment is set up (e.g., JupyterLab or VS Code with Jupyter extension).

## Usage

1. Open `WebScraping.ipynb` in a Jupyter environment.
2. Run the cells sequentially to fetch the webpage and execute the scraping functions.
3. Check the generated files in the working directory:
   - `Extract_Text_Data.CSV`
   - `Extract_Table_Data.CSV`
   - `Extract_Product_Information.json`
   - `Extract_Form_Details.json`
   - `Extract_Links_and_Multimedia.json`
   - `Scraping_Challenge.json`

## Project Structure

- **WebScraping.ipynb**: Main Jupyter Notebook containing the scraping logic.
- **Output Files**: CSV and JSON files generated by the scraping functions.
